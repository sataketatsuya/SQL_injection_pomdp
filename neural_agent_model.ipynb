{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import const\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import gym\n",
    "import ctfsql\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping, Any\n",
    "\n",
    "import numpy as np\n",
    "from ctfsql.agents.random_agent import Agent\n",
    "\n",
    "\n",
    "class RandomAgent(Agent):\n",
    "    \"\"\" Agent that randomly selects a command from the admissible ones. \"\"\"\n",
    "    def __init__(self, seed=1234):\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(self.seed)\n",
    "    \n",
    "    def act(self, obs: str, score: int, done: bool, infos: Mapping[str, Any]):\n",
    "        command_id = np.random.randint(0, len(infos[\"admissible_commands\"]))\n",
    "        command = infos[\"admissible_commands\"][command_id]\n",
    "        return command_id,  command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "            score = 0\n",
    "            sum_score = 0\n",
    "            done = False\n",
    "            nb_steps = 0\n",
    "            print(self.name, self.env.url, 'started')\n",
    "            while True:\n",
    "                command_id, command = self.agent.act(obs, score, done, infos)\n",
    "                print(self.name, command)\n",
    "                obs, score, done, infos = self.env.step(command_id, command)\n",
    "\n",
    "def run_episode(agent, max_step=2000, nb_episodes=1, verbose=True):\n",
    "    \n",
    "    torch.manual_seed(20211021)  # For reproducibility when using action sampling.\n",
    "\n",
    "    env = gym.make('ctfsql-v0')\n",
    "\n",
    "    try:\n",
    "        steps = np.load('steps.npy')\n",
    "        print('ステップ数ロード成功')\n",
    "    except:\n",
    "        steps = []\n",
    "    try:\n",
    "        mean_scores = np.load('mean_scores.npy')\n",
    "        print('平均報酬ロード成功')\n",
    "    except:\n",
    "        mean_scores = []\n",
    "        \n",
    "    for no_episode in tqdm(range(len(steps), nb_episodes)):\n",
    "        obs, infos = env.reset()  # Start new episode.\n",
    "\n",
    "        score = 0\n",
    "        sum_score = 0\n",
    "        done = False\n",
    "        nb_steps = 0\n",
    "        print(env.url)\n",
    "        while not done and nb_steps <= max_step:\n",
    "            command_id, command = agent.act(obs, score, done, infos)\n",
    "            obs, score, done, infos = env.step(command_id, command)\n",
    "            \n",
    "            nb_steps += 1\n",
    "            sum_score += score\n",
    "        agent.act(obs, score, done, infos)  # Let the agent know the game is done.\n",
    "\n",
    "        steps = np.append(steps, nb_steps)\n",
    "        mean_score = round(np.mean(sum_score), 3)\n",
    "        mean_scores = np.append(mean_scores, mean_score)\n",
    "        if verbose:\n",
    "            print('ステップ数:{0}, 平均報酬:{1}'.format(nb_steps, mean_score))\n",
    "\n",
    "#         print(steps, mean_scores)\n",
    "        if no_episode % 100 == 0:\n",
    "            np.save('steps', steps)\n",
    "            np.save('mean_scores', mean_scores)\n",
    "            joblib.dump(agent,'trained_agent.pkl', compress=True)\n",
    "    env.close()\n",
    "    return agent, steps, mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d066065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctfsql.agents.agent import NeuralAgent\n",
    "try:\n",
    "    agent = joblib.load('trained_agent.pkl')\n",
    "    print('エージェントロード成功')\n",
    "except:\n",
    "    agent = NeuralAgent()\n",
    "agent.train()\n",
    "trained_agent, steps, mean_scores = run_episode(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(steps)\n",
    "plt.title('neural agent plot')\n",
    "plt.xlabel('nb_episodes')\n",
    "plt.ylabel('steps per episode')\n",
    "fig.savefig(\"nn_agent.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
